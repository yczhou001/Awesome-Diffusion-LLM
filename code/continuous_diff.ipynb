{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Continuous Diffusion Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sinusoidal timestep embedding\n",
    "def get_timestep_embedding(timesteps, embedding_dim):\n",
    "    \"\"\"\n",
    "    Create sinusoidal timestep embeddings.\n",
    "    Args:\n",
    "        timesteps: [batch, 1] or [batch], int or float tensor\n",
    "        embedding_dim: int, embedding dimension\n",
    "    Returns:\n",
    "        [batch, embedding_dim] tensor\n",
    "    \"\"\"\n",
    "    if timesteps.dim() == 1:\n",
    "        timesteps = timesteps.unsqueeze(-1)  # [batch, 1]\n",
    "    half_dim = embedding_dim // 2\n",
    "    exponent = -np.log(10000) * torch.arange(half_dim, dtype=torch.float32, device=timesteps.device) / half_dim\n",
    "    emb = timesteps.float() * torch.exp(exponent)  # [batch, half_dim]\n",
    "    emb = torch.cat([torch.sin(emb), torch.cos(emb)], dim=-1)  # [batch, embedding_dim]\n",
    "    if embedding_dim % 2 == 1:\n",
    "        emb = F.pad(emb, (0, 1))\n",
    "    return emb\n",
    "    \n",
    "class SimpleMLP(nn.Module):  # Simple MLP as denoising model for noise prediction\n",
    "    def __init__(self, dim, t_emb_dim=32):\n",
    "        super().__init__()\n",
    "        self.t_emb_dim = t_emb_dim\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(dim + t_emb_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        # x: [batch, dim], t: [batch] or [batch, 1]\n",
    "        # t: timestep, will be encoded\n",
    "        t_emb = get_timestep_embedding(t, self.t_emb_dim)  # [batch, t_emb_dim]\n",
    "        xt = torch.cat([x, t_emb], dim=-1)\n",
    "        return self.net(xt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiffusionLMContinuous:\n",
    "    def __init__(self, dim, timesteps=1000, device='cpu', t_emb_dim=32):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dim: dimension of data (e.g. word embedding dim)\n",
    "            timesteps: number of diffusion steps (T)\n",
    "            device: torch device\n",
    "            t_emb_dim: dimension of timestep embedding\n",
    "        \"\"\"\n",
    "        self.dim = dim\n",
    "        self.timesteps = timesteps\n",
    "        self.device = device\n",
    "        self.beta = np.linspace(1e-4, 0.02, timesteps)  # Linear noise schedule\n",
    "        self.alpha = 1. - self.beta\n",
    "        self.alpha_bar = np.cumprod(self.alpha)\n",
    "        self.model = SimpleMLP(dim, t_emb_dim).to(device)\n",
    "        self.t_emb_dim = t_emb_dim\n",
    "        ## TODO: EMA.\n",
    "\n",
    "    def q_sample(self, x0, t):\n",
    "        \"\"\"\n",
    "        Forward process (add noise):\n",
    "            q(x_t | x_0) = sqrt(alpha_bar_t) * x_0 + sqrt(1 - alpha_bar_t) * epsilon\n",
    "        Args:\n",
    "            x0: [batch, dim], original data\n",
    "            t: [batch], timestep\n",
    "        Returns:\n",
    "            xt: [batch, dim], noisy data\n",
    "            noise: [batch, dim], added noise\n",
    "        \"\"\"\n",
    "        batch = x0.shape[0]\n",
    "        alpha_bar_t = torch.from_numpy(self.alpha_bar[t]).float().to(self.device)  # [batch]\n",
    "        alpha_bar_t = alpha_bar_t.view(-1, 1)\n",
    "        noise = torch.randn_like(x0)  # Gaussian noise\n",
    "        xt = torch.sqrt(alpha_bar_t) * x0 + torch.sqrt(1 - alpha_bar_t) * noise  # Add noise\n",
    "        return xt, noise\n",
    "\n",
    "    def p_sample(self, xt, t):\n",
    "        \"\"\"\n",
    "        Reverse process (denoise):\n",
    "            p(x_{t-1} | x_t) = N(mean, beta_t * I)\n",
    "            mean = (1 / sqrt(alpha_t)) * (x_t - (1 - alpha_t) / sqrt(1 - alpha_bar_t) * pred_noise)\n",
    "            x0_pred = (x_t - sqrt(1 - alpha_bar_t) * pred_noise) / sqrt(alpha_bar_t)\n",
    "        Args:\n",
    "            xt: [batch, dim], current noisy data\n",
    "            t: [batch], timestep (int or float)\n",
    "        Returns:\n",
    "            next_xt: [batch, dim], denoised data for previous step\n",
    "        \"\"\"\n",
    "        # t: [batch] or [batch, 1]\n",
    "        if isinstance(t, np.ndarray):\n",
    "            t = torch.from_numpy(t).to(self.device)\n",
    "        if t.dim() == 1:\n",
    "            t = t.view(-1)\n",
    "        pred_noise = self.model(xt, t)  # using the model.\n",
    "        alpha_t = torch.from_numpy(self.alpha[t.cpu().numpy()]).float().to(self.device).view(-1, 1)\n",
    "        alpha_bar_t = torch.from_numpy(self.alpha_bar[t.cpu().numpy()]).float().to(self.device).view(-1, 1)\n",
    "        beta_t = torch.from_numpy(self.beta[t.cpu().numpy()]).float().to(self.device).view(-1, 1)\n",
    "        sqrt_one_minus_alpha_bar_t = torch.sqrt(1 - alpha_bar_t)\n",
    "        mean = (1 / torch.sqrt(alpha_t)) * (xt - (1 - alpha_t) / sqrt_one_minus_alpha_bar_t * pred_noise)\n",
    "        if t[0] > 0:\n",
    "            noise = torch.randn_like(xt)\n",
    "            mean = mean + torch.sqrt(beta_t) * noise\n",
    "        return mean\n",
    "\n",
    "    def train_step(self, x0, optimizer):\n",
    "        batch = x0.shape[0]\n",
    "        t = np.random.randint(0, self.timesteps, size=(batch,))  # Random timestep\n",
    "        t_tensor = torch.tensor(t, dtype=torch.long, device=self.device)\n",
    "        xt, noise = self.q_sample(x0, t)  # Add noise\n",
    "        pred_noise = self.model(xt, t_tensor)  # Predict noise (t_tensor will be encoded)\n",
    "        loss = F.mse_loss(pred_noise, noise)  # MSE loss\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # TODO: EMA.\n",
    "        \n",
    "        return loss.item()\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        xt = torch.randn(batch_size, self.dim, device=self.device)  # Start from pure noise.\n",
    "        # TODO: Classifier-free guidance.\n",
    "        for t in reversed(range(self.timesteps)):\n",
    "            t_arr = np.full((batch_size,), t)\n",
    "            xt = self.p_sample(xt, t_arr)  # Using the model.\n",
    "        return xt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 1.0513\n",
      "Epoch 100, Loss: 0.5817\n",
      "Epoch 200, Loss: 0.5004\n",
      "Epoch 300, Loss: 0.4290\n",
      "Epoch 400, Loss: 0.3646\n",
      "sampling shape: (5, 8)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Suppose we have a simple word vector space, each word is a vector.\n",
    "This demo is only for illustrating the basic principles of continuous diffusion models. \n",
    "Actual diffusion language modeling requires more complex encoding and decoding strategies.\n",
    "'''\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "dim = 8\n",
    "lm = DiffusionLMContinuous(dim, timesteps=100, device=device)\n",
    "optimizer = torch.optim.Adam(lm.model.parameters(), lr=1e-3)\n",
    "\n",
    "# Build a simple training set.\n",
    "x0 = torch.randn((10,dim), device=device)\n",
    "x0 = x0.repeat(100, 1)  # batch=100\n",
    "\n",
    "# Training\n",
    "for ep in range(500):\n",
    "    loss = lm.train_step(x0, optimizer)\n",
    "    if ep % 100 == 0:\n",
    "        print(f'Epoch {ep}, Loss: {loss:.4f}')\n",
    "\n",
    "# Sampling\n",
    "samples = lm.sample(5).detach().cpu().numpy()\n",
    "print('sampling shape:', samples.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "T2I",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
